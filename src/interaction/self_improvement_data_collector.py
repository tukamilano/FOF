"""
Self Improvement Data Collector
è§£ã‘ãŸexampleã®æˆåŠŸã—ãŸã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã®ã¿ã‚’åé›†ã—ã¦å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿å­˜ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
from __future__ import annotations

import argparse
import os
import sys
import json
import time
import hashlib
import random
import numpy as np
from typing import List, Tuple, Dict, Any
from tqdm import tqdm

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
sys.path.insert(0, project_root)

import torch
import re

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å®šæ•°ï¼ˆä¸€åº¦ã ã‘åˆæœŸåŒ–ï¼‰
PYPROVER_MODULES = None
GENERATION_PARAMS = None
BASE_TOKENS = None
TACTIC_PARSER_CACHE = {}


def detect_double_negation_loop(goal: str, max_nesting: int = 6) -> bool:
    """
    äºŒé‡å¦å®šã®ç„¡é™ãƒ«ãƒ¼ãƒ—ã‚’æ¤œå‡º

    Args:
        goal: ç›®æ¨™ã®è«–ç†å¼
        max_nesting: æœ€å¤§ãƒã‚¹ãƒˆãƒ¬ãƒ™ãƒ«

    Returns:
        True if double negation loop detected
    """
    if not isinstance(goal, str):
        return False

    # ã‚ˆã‚Šå³å¯†ãªäºŒé‡å¦å®šãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º: é€£ç¶šã™ã‚‹æ·±ã„ãƒã‚¹ãƒˆ
    # ãƒ‘ã‚¿ãƒ¼ãƒ³: ((((X â†’ False) â†’ False) â†’ False) â†’ False)...
    double_negation_pattern = r'\([^)]*â†’\s*False\)\s*â†’\s*False'

    # ãƒã‚¹ãƒˆãƒ¬ãƒ™ãƒ«ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    nesting_level = 0
    current_goal = goal

    # é€£ç¶šã™ã‚‹äºŒé‡å¦å®šã®æ·±ã•ã‚’ãƒã‚§ãƒƒã‚¯
    while re.search(double_negation_pattern, current_goal):
        nesting_level += 1
        if nesting_level > max_nesting:
            return True

        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç½®æ›ã—ã¦æ¬¡ã®ãƒ¬ãƒ™ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—å‚ç…§ã‚’ä¿®æ­£ï¼‰
        current_goal = re.sub(double_negation_pattern, r'(\g<0>)', current_goal)

        # ç„¡é™ãƒ«ãƒ¼ãƒ—ã‚’é˜²ã
        if nesting_level > 10:
            break

    # è¿½åŠ ãƒã‚§ãƒƒã‚¯: çŸ¢å°æ•°ã¨Falseå‡ºç¾æ•°ã«ã‚ˆã‚‹äºŒé‡å¦å®šãƒ«ãƒ¼ãƒ—æ¤œå‡º
    arrow_count = goal.count('â†’')
    false_count = goal.count('False')

    if arrow_count >= 5 and false_count >= 5:
        return True

    return False


from src.core.transformer_classifier import (
    load_tokens_and_labels_from_token_py,
    CharTokenizer,
    TransformerClassifier,
)
from src.core.state_encoder import encode_prover_state, format_tactic_string


def load_tautologies_from_generated_data(
    generated_data_dir: str = "generated_data",
    max_examples: int = None
) -> List[str]:
    """
    generated_dataé…ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è«–ç†å¼ã‚’èª­ã¿å‡ºã™
    
    Args:
        generated_data_dir: generated_dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
        max_examples: èª­ã¿è¾¼ã‚€æœ€å¤§ä¾‹æ•°ï¼ˆNoneã®å ´åˆã¯å…¨ã¦ï¼‰
    
    Returns:
        è«–ç†å¼ã®ãƒªã‚¹ãƒˆ
    """
    tautologies = []
    
    # generated_dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    if not os.path.exists(generated_data_dir):
        print(f"Warning: Generated data directory not found: {generated_data_dir}")
        return []
    
    json_files = [f for f in os.listdir(generated_data_dir) if f.endswith('.json')]
    json_files.sort()  # ãƒ•ã‚¡ã‚¤ãƒ«åã§ã‚½ãƒ¼ãƒˆ
    
    if not json_files:
        return []
    
    
    for json_file in json_files:
        if max_examples and len(tautologies) >= max_examples:
            break
            
        file_path = os.path.join(generated_data_dir, json_file)
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if isinstance(data, list):
                # ãƒªã‚¹ãƒˆå½¢å¼ã®å ´åˆ
                for formula in data:
                    if max_examples and len(tautologies) >= max_examples:
                        break
                    if isinstance(formula, str) and formula.strip():
                        tautologies.append(formula.strip())
            elif isinstance(data, dict):
                # è¾æ›¸å½¢å¼ã®å ´åˆï¼ˆå°†æ¥çš„ãªæ‹¡å¼µã«å¯¾å¿œï¼‰
                if 'formulas' in data and isinstance(data['formulas'], list):
                    for formula in data['formulas']:
                        if max_examples and len(tautologies) >= max_examples:
                            break
                        if isinstance(formula, str) and formula.strip():
                            tautologies.append(formula.strip())
            
            
        except Exception as e:
            print(f"Warning: Failed to load {json_file}: {e}")
            continue
    
    return tautologies


def initialize_global_constants():
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«å®šæ•°ã‚’ä¸€åº¦ã ã‘åˆæœŸåŒ–"""
    global PYPROVER_MODULES, GENERATION_PARAMS, BASE_TOKENS
    
    if PYPROVER_MODULES is None:
        # pyproverãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’åˆæœŸåŒ–
        pyprover_dir = os.path.join(project_root, "pyprover")
        
        # ãƒ‘ã‚¹ã‚’è¿½åŠ 
        if pyprover_dir not in sys.path:
            sys.path.insert(0, pyprover_dir)
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å¤‰æ›´ã—ã¦ã‹ã‚‰ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
        original_cwd = os.getcwd()
        os.chdir(pyprover_dir)
        
        try:
            # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            import proposition as proposition_mod
            import prover as prover_mod
            
            PYPROVER_MODULES = {
                'PropParseTree': proposition_mod.PropParseTree,
                'prop_parser': proposition_mod.parser,
                'Prover': prover_mod.Prover
            }
            print(f"PYPROVER_MODULES initialized successfully")
        except Exception as e:
            print(f"Error initializing PYPROVER_MODULES: {e}")
            import traceback
            traceback.print_exc()
            PYPROVER_MODULES = None
        finally:
            os.chdir(original_cwd)
    
    if GENERATION_PARAMS is None:
        from src.core.parameter import get_generation_params
        GENERATION_PARAMS = get_generation_params()
    
    if BASE_TOKENS is None:
        token_py_path = os.path.join(project_root, "src", "core", "fof_tokens.py")
        BASE_TOKENS, _ = load_tokens_and_labels_from_token_py(token_py_path)


def parse_tactic_string_cached(tactic_str: str) -> Dict[str, Any]:
    """ã‚¿ã‚¯ãƒ†ã‚£ã‚¯æ–‡å­—åˆ—ã‚’ãƒ‘ãƒ¼ã‚¹ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãï¼‰"""
    if tactic_str not in TACTIC_PARSER_CACHE:
        parts = tactic_str.split()
        
        if len(parts) == 1:
            TACTIC_PARSER_CACHE[tactic_str] = {
                "main": parts[0],
                "arg1": None,
                "arg2": None
            }
        elif len(parts) == 2:
            TACTIC_PARSER_CACHE[tactic_str] = {
                "main": parts[0],
                "arg1": parts[1],
                "arg2": None
            }
        elif len(parts) == 3:
            TACTIC_PARSER_CACHE[tactic_str] = {
                "main": parts[0],
                "arg1": parts[1],
                "arg2": parts[2]
            }
        else:
            TACTIC_PARSER_CACHE[tactic_str] = {
                "main": tactic_str,
                "arg1": None,
                "arg2": None
            }
    
    return TACTIC_PARSER_CACHE[tactic_str]


def create_state_hash(premises: List[str], goal: str, tactic_str: str) -> str:
    """çŠ¶æ…‹ãƒãƒƒã‚·ãƒ¥ã‚’åŠ¹ç‡çš„ã«ä½œæˆ"""
    # æ–‡å­—åˆ—çµåˆã‚’æœ€é©åŒ–
    state_tactic_str = f"{'|'.join(premises)}|{goal}|{tactic_str}"
    return hashlib.md5(state_tactic_str.encode()).hexdigest()


def save_buffer_data(
    successful_buffer: List[Dict[str, Any]],
    failed_buffer: List[Dict[str, Any]],
    output_dir: str,
    batch_counter: int,
    batch_size: int,
    gcs_bucket: str = None,
    gcs_prefix: str = ""
) -> int:
    """ãƒãƒƒãƒ•ã‚¡ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    if not output_dir:
        return batch_counter
    
    os.makedirs(output_dir, exist_ok=True)
    
    # æˆåŠŸãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    if successful_buffer:
        filename = f"successful_tactics_{batch_counter:05d}.json"
        filepath = os.path.join(output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(successful_buffer, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ Saved {len(successful_buffer)} successful tactics to {filepath}")
        
        # GCSã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if gcs_bucket:
            try:
                from google.cloud import storage
                client = storage.Client()
                bucket = client.bucket(gcs_bucket)
                blob_name = f"{gcs_prefix.rstrip('/')}/{filename}" if gcs_prefix else filename
                blob = bucket.blob(blob_name)
                blob.upload_from_filename(filepath)
                print(f"âœ… Uploaded {filename} to GCS")
            except Exception as e:
                print(f"âŒ Failed to upload {filename} to GCS: {e}")
    
    # å¤±æ•—ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    if failed_buffer:
        filename = f"failed_tactics_{batch_counter:05d}.json"
        filepath = os.path.join(output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(failed_buffer, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ Saved {len(failed_buffer)} failed tactics to {filepath}")
        
        # GCSã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if gcs_bucket:
            try:
                from google.cloud import storage
                client = storage.Client()
                bucket = client.bucket(gcs_bucket)
                blob_name = f"{gcs_prefix.rstrip('/')}/{filename}" if gcs_prefix else filename
                blob = bucket.blob(blob_name)
                blob.upload_from_filename(filepath)
                print(f"âœ… Uploaded {filename} to GCS")
            except Exception as e:
                print(f"âŒ Failed to upload {filename} to GCS: {e}")
    
    return batch_counter + 1


def load_hierarchical_model(model_path: str, device: torch.device) -> Tuple[TransformerClassifier, Dict[str, Any]]:
    """éšå±¤åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    checkpoint = torch.load(model_path, map_location=device)
    
    # æ–°ã—ã„å½¢å¼ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã©ã†ã‹ã‚’åˆ¤å®š
    if 'model_params' in checkpoint:
        # æ–°ã—ã„å½¢å¼ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ
        model_params = checkpoint['model_params']
        vocab_size = checkpoint.get('vocab_size', model_params['vocab_size'])
        pad_id = checkpoint.get('pad_id', model_params['pad_id'])
        max_seq_len = checkpoint.get('max_seq_len', model_params['max_seq_len'])
        
        # ã‚¯ãƒ©ã‚¹æ•°ã‚’ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å–å¾—
        num_main_classes = len(checkpoint['id_to_main'])
        num_arg1_classes = len(checkpoint['id_to_arg1'])
        num_arg2_classes = len(checkpoint['id_to_arg2'])
        
        # ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å–å¾—
        label_mappings = {
            'main_to_id': checkpoint['main_to_id'],
            'arg1_to_id': checkpoint['arg1_to_id'],
            'arg2_to_id': checkpoint['arg2_to_id'],
            'id_to_main': checkpoint['id_to_main'],
            'id_to_arg1': checkpoint['id_to_arg1'],
            'id_to_arg2': checkpoint['id_to_arg2'],
        }
        
        model = TransformerClassifier(
            vocab_size=vocab_size,
            pad_id=pad_id,
            max_seq_len=max_seq_len,
            d_model=model_params['d_model'],
            nhead=model_params['nhead'],
            num_layers=model_params['num_layers'],
            dim_feedforward=model_params['dim_feedforward'],
            dropout=model_params['dropout'],
            num_main_classes=num_main_classes,
            num_arg1_classes=num_arg1_classes,
            num_arg2_classes=num_arg2_classes,
        )
        
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        # å¤ã„å½¢å¼ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆï¼ˆé‡ã¿ã®ã¿ï¼‰
        print("Loading old format checkpoint (weights only)")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
        from src.core.parameter import get_model_params
        model_params = get_model_params()
        
        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰vocab_sizeã‚’å–å¾—ï¼ˆembeddingå±¤ã®ã‚µã‚¤ã‚ºã‹ã‚‰ï¼‰
        vocab_size = checkpoint['embedding.weight'].shape[0]
        print(f"Detected vocab_size from checkpoint: {vocab_size}")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°ã‚’å–å¾—
        from src.core.parameter import get_hierarchical_labels
        from src.core.transformer_classifier import build_hierarchical_label_mappings
        hierarchical_labels = get_hierarchical_labels()
        main_to_id, arg1_to_id, arg2_to_id, id_to_main, id_to_arg1, id_to_arg2 = build_hierarchical_label_mappings(
            hierarchical_labels.main_tactics,
            hierarchical_labels.arg1_values,
            hierarchical_labels.arg2_values
        )
        
        label_mappings = {
            'main_to_id': main_to_id,
            'arg1_to_id': arg1_to_id,
            'arg2_to_id': arg2_to_id,
            'id_to_main': id_to_main,
            'id_to_arg1': id_to_arg1,
            'id_to_arg2': id_to_arg2,
        }
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆï¼ˆãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‹ã‚‰å–å¾—ã—ãŸvocab_sizeã‚’ä½¿ç”¨ï¼‰
        model = TransformerClassifier(
            vocab_size=vocab_size,
            pad_id=model_params.pad_id,
            max_seq_len=model_params.max_seq_len,
            d_model=model_params.d_model,
            nhead=model_params.nhead,
            num_layers=model_params.num_layers,
            dim_feedforward=model_params.dim_feedforward,
            dropout=model_params.dropout,
            num_main_classes=len(id_to_main),
            num_arg1_classes=len(id_to_arg1),
            num_arg2_classes=len(id_to_arg2),
        )
        
        # é‡ã¿ã‚’èª­ã¿è¾¼ã¿
        model.load_state_dict(checkpoint)
    
    model.to(device)
    model.eval()
    
    return model, label_mappings


def calculate_tactic_probability(
    main_tactic: str,
    arg1_value: str,
    arg2_value: str,
    main_confidence: float,
    arg1_confidence: float,
    arg2_confidence: float
) -> float:
    """
    ã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã®ç¨®é¡ã«å¿œã˜ã¦é©åˆ‡ãªç¢ºç‡ã‚’è¨ˆç®—
    
    Args:
        main_tactic: ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¯ãƒ†ã‚£ã‚¯
        arg1_value: ç¬¬1å¼•æ•°
        arg2_value: ç¬¬2å¼•æ•°
        main_confidence: ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã®ç¢ºä¿¡åº¦
        arg1_confidence: ç¬¬1å¼•æ•°ã®ç¢ºä¿¡åº¦
        arg2_confidence: ç¬¬2å¼•æ•°ã®ç¢ºä¿¡åº¦
    
    Returns:
        è¨ˆç®—ã•ã‚ŒãŸç¢ºç‡
    """
    # å¼•æ•°ä¸è¦ãªã‚¿ã‚¯ãƒ†ã‚£ã‚¯
    if main_tactic in ['assumption', 'intro', 'split', 'left', 'right', 'add_dn']:
        return main_confidence
    
    # å¼•æ•°1ã¤ã®ã‚¿ã‚¯ãƒ†ã‚£ã‚¯
    elif main_tactic in ['apply', 'destruct']:
        return main_confidence * arg1_confidence
    
    # å¼•æ•°2ã¤ã®ã‚¿ã‚¯ãƒ†ã‚£ã‚¯
    elif main_tactic == 'specialize':
        return main_confidence * arg1_confidence * arg2_confidence
    
    # ãã®ä»–ã®ã‚¿ã‚¯ãƒ†ã‚£ã‚¯ï¼ˆå¼•æ•°ä¸è¦ã¨ã—ã¦æ‰±ã†ï¼‰
    else:
        return main_confidence


def select_tactic_probabilistically(
    tactic_combinations: List[Tuple[str, float]], 
    temperature: float = 1.0,
    failed_tactics: set = None
) -> Tuple[str, float]:
    """
    temperatureã‚’ä½¿ç”¨ã—ã¦ã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã‚’ç¢ºç‡çš„ã«é¸æŠ
    
    Args:
        tactic_combinations: [(tactic_string, probability), ...] ã®ãƒªã‚¹ãƒˆ
        temperature: æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆé«˜ã„ã»ã©ãƒ©ãƒ³ãƒ€ãƒ ã€ä½ã„ã»ã©ç¢ºç‡ã«å¾“ã†ï¼‰
        failed_tactics: å¤±æ•—ã—ãŸã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã®ã‚»ãƒƒãƒˆ
    
    Returns:
        é¸æŠã•ã‚ŒãŸã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã¨ãã®èª¿æ•´å¾Œã®ç¢ºç‡
    """
    if failed_tactics is None:
        failed_tactics = set()
    
    # å¤±æ•—ã—ã¦ã„ãªã„ã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    available_tactics = [(tactic, prob) for tactic, prob in tactic_combinations 
                        if tactic not in failed_tactics]
    
    if not available_tactics:
        # åˆ©ç”¨å¯èƒ½ãªã‚¿ã‚¯ãƒ†ã‚£ã‚¯ãŒãªã„å ´åˆã¯ç©ºã‚’è¿”ã™
        return "", 0.0
    
    # ç¢ºç‡ã‚’æ¸©åº¦ã§èª¿æ•´
    tactics, probabilities = zip(*available_tactics)
    probabilities = np.array(probabilities)
    
    # æ¸©åº¦ã‚’é©ç”¨ï¼ˆlogç¢ºç‡ã«å¤‰æ›ã—ã¦ã‹ã‚‰æ¸©åº¦ã§å‰²ã‚‹ï¼‰
    log_probs = np.log(probabilities + 1e-8)  # æ•°å€¤å®‰å®šæ€§ã®ãŸã‚å°ã•ãªå€¤ã‚’è¿½åŠ 
    scaled_log_probs = log_probs / temperature
    
    # softmaxã§æ­£è¦åŒ–
    exp_probs = np.exp(scaled_log_probs - np.max(scaled_log_probs))  # æ•°å€¤å®‰å®šæ€§ã®ãŸã‚
    softmax_probs = exp_probs / np.sum(exp_probs)
    
    # ç¢ºç‡çš„ã«é¸æŠ
    selected_idx = np.random.choice(len(tactics), p=softmax_probs)
    selected_tactic = tactics[selected_idx]
    selected_prob = softmax_probs[selected_idx]  # èª¿æ•´å¾Œã®ç¢ºç‡ã‚’è¿”ã™
    
    return selected_tactic, selected_prob


def generate_tactic_combinations(
    model: TransformerClassifier,
    tokenizer: CharTokenizer,
    premises: List[str],
    goal: str,
    label_mappings: Dict[str, Any],
    device: torch.device,
    max_seq_len: int = 256,
    temperature: float = 1.0
) -> List[Tuple[str, float]]:
    """
    ã™ã¹ã¦ã®å¯èƒ½ãªã‚¿ã‚¯ãƒ†ã‚£ã‚¯çµ„ã¿åˆã‚ã›ã‚’ç”Ÿæˆ
    
    Returns:
        [(tactic_string, probability), ...] ã®ãƒªã‚¹ãƒˆï¼ˆç¢ºç‡ã®é«˜ã„é †ï¼‰
    """
    
    # å…¥åŠ›ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    input_ids, attention_mask, segment_ids = tokenizer.encode(goal, premises, max_seq_len)
    input_ids = input_ids.unsqueeze(0).to(device)
    attention_mask = attention_mask.unsqueeze(0).to(device)
    segment_ids = segment_ids.unsqueeze(0).to(device)
    
    with torch.no_grad():
        main_logits, arg1_logits, arg2_logits = model(input_ids, attention_mask)
        
        # temperatureã‚’é©ç”¨ã—ã¦softmaxã§ç¢ºç‡ã«å¤‰æ›
        if temperature == 0.0:
            # temperature=0ã®å ´åˆã¯ç¢ºå®šçš„ï¼ˆsoftmaxã§ç¢ºç‡ã‚’è¨ˆç®—ã—ã€ç¢ºç‡ã®é«˜ã„é †ã«è©¦ã™ï¼‰
            main_probs = torch.softmax(main_logits, dim=-1)
            arg1_probs = torch.softmax(arg1_logits, dim=-1)
            arg2_probs = torch.softmax(arg2_logits, dim=-1)
        else:
            # temperature>0ã®å ´åˆã¯softmax
            main_probs = torch.softmax(main_logits / temperature, dim=-1)
            arg1_probs = torch.softmax(arg1_logits / temperature, dim=-1)
            arg2_probs = torch.softmax(arg2_logits / temperature, dim=-1)
        
        # ç¢ºç‡é–¾å€¤ã‚’æº€ãŸã™ã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã‚’åé›†
        tactic_combinations = []
        
        # å¼•æ•°ãŒä¸è¦ãªã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã‚’å‡¦ç†
        for main_id, main_tactic in enumerate(label_mappings['id_to_main']):
            main_confidence = main_probs[0, main_id].item()
            
            if main_tactic in ['assumption', 'intro', 'split', 'left', 'right', 'add_dn']:
                tactic_string = main_tactic
                probability = calculate_tactic_probability(
                    main_tactic, "", "",
                    main_confidence, 0.0, 0.0
                )
                
                tactic_combinations.append((tactic_string, probability))
            
            # å¼•æ•°1ã¤ã®ã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã®å ´åˆ
            elif main_tactic in ['apply', 'destruct']:
                for arg1_id, arg1_value in enumerate(label_mappings['id_to_arg1']):
                    arg1_confidence = arg1_probs[0, arg1_id].item()
                    
                    tactic_string = f"{main_tactic} {arg1_value}"
                    probability = calculate_tactic_probability(
                        main_tactic, arg1_value, "",
                        main_confidence, arg1_confidence, 0.0
                    )
                    
                    tactic_combinations.append((tactic_string, probability))
            
            # å¼•æ•°2ã¤ã®ã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã®å ´åˆ
            elif main_tactic == 'specialize':
                for arg1_id, arg1_value in enumerate(label_mappings['id_to_arg1']):
                    arg1_confidence = arg1_probs[0, arg1_id].item()
                    
                    for arg2_id, arg2_value in enumerate(label_mappings['id_to_arg2']):
                        arg2_confidence = arg2_probs[0, arg2_id].item()
                        
                        tactic_string = f"{main_tactic} {arg1_value} {arg2_value}"
                        probability = calculate_tactic_probability(
                            main_tactic, arg1_value, arg2_value,
                            main_confidence, arg1_confidence, arg2_confidence
                        )
                        
                        tactic_combinations.append((tactic_string, probability))
            
            # ãã®ä»–ã®ã‚¿ã‚¯ãƒ†ã‚£ã‚¯ï¼ˆå¼•æ•°ä¸è¦ã¨ã—ã¦æ‰±ã†ï¼‰
            else:
                tactic_string = main_tactic
                probability = calculate_tactic_probability(
                    main_tactic, "", "",
                    main_confidence, 0.0, 0.0
                )
                
                tactic_combinations.append((tactic_string, probability))
        
        # ç¢ºç‡ã®é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
        tactic_combinations.sort(key=lambda x: x[1], reverse=True)
        
        return tactic_combinations


def apply_tactic_from_label(prover, label) -> bool:
    """ã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã‚’é©ç”¨"""
    if isinstance(label, dict):
        tactic_str = format_tactic_string(label)
    else:
        tactic_str = label
    
    try:
        if tactic_str == "assumption":
            return not prover.assumption()
        if tactic_str == "intro":
            return not prover.intro()
        if tactic_str == "split":
            return not prover.split()
        if tactic_str == "left":
            return not prover.left()
        if tactic_str == "right":
            return not prover.right()
        if tactic_str == "add_dn":
            return not prover.add_dn()
        
        parts = tactic_str.split()
        if parts[0] == "apply" and len(parts) == 2 and parts[1].isdigit():
            idx = int(parts[1])
            if idx >= len(prover.variables):
                return False
            return not prover.apply(idx)
        if parts[0] == "destruct" and len(parts) == 2 and parts[1].isdigit():
            idx = int(parts[1])
            if idx >= len(prover.variables):
                return False
            return not prover.destruct(idx)
        if parts[0] == "specialize" and len(parts) == 3 and parts[1].isdigit() and parts[2].isdigit():
            func_idx = int(parts[1])
            domain_idx = int(parts[2])
            if func_idx >= len(prover.variables) or domain_idx >= len(prover.variables):
                return False
            return not prover.specialize(func_idx, domain_idx)
        return False
    except Exception as e:
        # pyproverã®ã‚¨ãƒ©ãƒ¼ã‚’ã‚­ãƒ£ãƒƒãƒã—ã¦Falseã‚’è¿”ã™
        return False




def collect_self_improvement_data(
    model: TransformerClassifier,
    tokenizer: CharTokenizer,
    label_mappings: Dict[str, Any],
    device: torch.device,
    max_seq_len: int,
    num_examples: int = 100,
    max_steps: int = 30,
    verbose: bool = False,
    generated_data_dir: str = "generated_data",
    temperature: float = 1.0
) -> List[Dict[str, Any]]:
    """
    Self improvementç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ï¼ˆæˆåŠŸãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
    
    Args:
        generated_data_dir: generated_dataãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
    
    Returns:
        æˆåŠŸã—ãŸã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã®ãƒªã‚¹ãƒˆï¼ˆdeduplicated_batchå½¢å¼ï¼‰
    """
    successful_tactics, _ = collect_comprehensive_rl_data(
        model, tokenizer, label_mappings, device, max_seq_len,
        num_examples, max_steps, verbose, generated_data_dir, temperature,
        include_failures=False
    )
    return successful_tactics


def collect_comprehensive_rl_data(
    model: TransformerClassifier,
    tokenizer: CharTokenizer,
    label_mappings: Dict[str, Any],
    device: torch.device,
    max_seq_len: int,
    num_examples: int = 100,
    max_steps: int = 30,
    verbose: bool = False,
    generated_data_dir: str = "generated_data",
    temperature: float = 1.0,
    include_failures: bool = True,
    success_reward: float = 1.0,
    step_penalty: float = 0.01,
    failure_penalty: float = -0.1,
    output_dir: str = None,
    batch_size: int = 1000,
    gcs_bucket: str = None,
    gcs_prefix: str = ""
) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
    """
    Actor-Criticå­¦ç¿’ç”¨ã®åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ï¼ˆæˆåŠŸãƒ»å¤±æ•—ä¸¡æ–¹ï¼‰
    
    Args:
        model: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        tokenizer: ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼
        label_mappings: ãƒ©ãƒ™ãƒ«ãƒãƒƒãƒ”ãƒ³ã‚°
        device: ãƒ‡ãƒã‚¤ã‚¹
        max_seq_len: æœ€å¤§ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·
        num_examples: å‡¦ç†ã™ã‚‹ä¾‹æ•°
        max_steps: æœ€å¤§ã‚¹ãƒ†ãƒƒãƒ—æ•°
        verbose: è©³ç´°å‡ºåŠ›ãƒ•ãƒ©ã‚°
        generated_data_dir: ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        temperature: æ¸©åº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        include_failures: å¤±æ•—ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ã‹ã©ã†ã‹
        success_reward: æˆåŠŸæ™‚ã®å ±é…¬
        step_penalty: ã‚¹ãƒ†ãƒƒãƒ—ãƒšãƒŠãƒ«ãƒ†ã‚£
        failure_penalty: å¤±æ•—æ™‚ã®ãƒšãƒŠãƒ«ãƒ†ã‚£
    
    Returns:
        (successful_tactics, failed_tactics) ã®ã‚¿ãƒ—ãƒ«
    """
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«å®šæ•°ã‚’åˆæœŸåŒ–
    initialize_global_constants()
    
    # generated_dataé…ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è«–ç†å¼ã‚’èª­ã¿è¾¼ã¿
    tautologies = load_tautologies_from_generated_data(
        generated_data_dir=generated_data_dir,
        max_examples=num_examples
    )
    
    if not tautologies:
        print("Failed to load tautologies from generated_data directory!")
        return [], []
    
    
    # æˆåŠŸãƒ»å¤±æ•—ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    successful_tactics = []
    failed_tactics = []
    solved_count = 0
    
    # é€æ¬¡æ›¸ãå‡ºã—ç”¨ã®ãƒãƒƒãƒ•ã‚¡
    successful_buffer = []
    failed_buffer = []
    batch_counter = 0
    
    # ãƒ«ãƒ¼ãƒ—å®Ÿè¡Œ
    for i, goal_str in enumerate(tautologies):
        try:
            # ãƒ‘ãƒ¼ã‚¹ã—ã¦proverã‚’ä½œæˆ
            parse_tree = PYPROVER_MODULES['PropParseTree']()
            goal_node = parse_tree.transform(PYPROVER_MODULES['prop_parser'].parse(goal_str))
            prover = PYPROVER_MODULES['Prover'](goal_node)
            
            # å‰æã¯ç©ºï¼ˆãƒˆãƒ¼ãƒˆãƒ­ã‚¸ãƒ¼ãªã®ã§å‰æãªã—ã§è¨¼æ˜å¯èƒ½ï¼‰
            premises = []
            
            
            # ã“ã®exampleã®æˆåŠŸãƒ»å¤±æ•—ã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã‚’ä¸€æ™‚çš„ã«ä¿å­˜
            example_successful_tactics = []
            example_failed_tactics = []
            
            # å¤±æ•—ã—ãŸã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã‚’è¨˜éŒ²ã™ã‚‹ã‚»ãƒƒãƒˆï¼ˆã“ã®exampleå†…ã§ã®ã¿æœ‰åŠ¹ï¼‰
            failed_tactic_strings = set()
            
            # æ¨è«–ãƒ«ãƒ¼ãƒ—
            step = 0
            solved = prover.goal is None
            example_terminated = False  # exampleå…¨ä½“ã®æ—©æœŸçµ‚äº†ãƒ•ãƒ©ã‚°
            consecutive_failures = 0  # é€£ç¶šå¤±æ•—æ•°ã‚’ã‚¹ãƒ†ãƒƒãƒ—é–“ã§ä¿æŒ
            
            while not solved and step < max_steps and not example_terminated:
                # ç¾åœ¨ã®çŠ¶æ…‹ã‚’å–å¾—
                current_state = encode_prover_state(prover)
                current_premises = current_state["premises"]
                current_goal = current_state["goal"]
                
                # äºŒé‡å¦å®šãƒ«ãƒ¼ãƒ—ã‚’æ¤œå‡ºã—ãŸå ´åˆã¯æ—©æœŸçµ‚äº†
                if current_goal and detect_double_negation_loop(str(current_goal)):
                    example_terminated = True
                    break
                
                
                # ç¢ºç‡é–¾å€¤ã‚’æº€ãŸã™ã‚¿ã‚¯ãƒ†ã‚£ã‚¯çµ„ã¿åˆã‚ã›ã‚’ç”Ÿæˆ
                tactic_combinations = generate_tactic_combinations(
                    model, tokenizer, current_premises, current_goal,
                    label_mappings, device, max_seq_len, temperature
                )
                
                
                # ç¢ºç‡çš„ã«ã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã‚’é¸æŠã—ã¦é©ç”¨
                success = False
                max_attempts = len(tactic_combinations)  # åˆ©ç”¨å¯èƒ½ãªã‚¿ã‚¯ãƒ†ã‚£ã‚¯æ•°
                attempts = 0
                
                # åˆ©ç”¨å¯èƒ½ãªã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã‚’äº‹å‰ã«è¨ˆç®—
                available_tactics = [tactic for tactic, _ in tactic_combinations 
                                   if tactic not in failed_tactic_strings]
                
                while not success and attempts < max_attempts and not example_terminated and available_tactics:
                    # ç¢ºç‡çš„ã«ã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã‚’é¸æŠ
                    selected_tactic, selected_prob = select_tactic_probabilistically(
                        tactic_combinations, temperature, failed_tactic_strings
                    )
                    
                    if not selected_tactic:
                        # åˆ©ç”¨å¯èƒ½ãªã‚¿ã‚¯ãƒ†ã‚£ã‚¯ãŒãªã„å ´åˆ
                        example_terminated = True
                        break
                    
                    # ã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã‚’é©ç”¨
                    success = apply_tactic_from_label(prover, selected_tactic)
                    attempts += 1
                    
                    
                    if success:
                        # æˆåŠŸã—ãŸã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã‚’ä¸€æ™‚çš„ã«è¨˜éŒ²
                        tactic_dict = parse_tactic_string_cached(selected_tactic)
                        state_tactic_hash = create_state_hash(current_premises, current_goal, selected_tactic)
                        
                        # å ±é…¬è¨ˆç®—
                        reward = success_reward if prover.goal is None else 0.0
                        
                        example_successful_tactics.append({
                            "step_index": step,
                            "premises": current_premises.copy(),
                            "goal": current_goal,
                            "tactic": tactic_dict,
                            "tactic_apply": True,
                            "state_tactic_hash": state_tactic_hash,
                            "reward": reward,
                            "log_prob": np.log(selected_prob + 1e-8)  # å¯¾æ•°ç¢ºç‡
                        })
                        consecutive_failures = 0  # æˆåŠŸã—ãŸã‚‰é€£ç¶šå¤±æ•—æ•°ã‚’ãƒªã‚»ãƒƒãƒˆ
                        
                        # æˆåŠŸã—ãŸãŒæœ€çµ‚çš„ã«è¨¼æ˜ãŒå®Œäº†ã—ãªã‹ã£ãŸå ´åˆã€å¤±æ•—ãƒ‡ãƒ¼ã‚¿ã«ã‚‚è¿½åŠ 
                        # ãŸã ã—ã€åŸºæœ¬çš„ãªã‚¿ã‚¯ãƒ†ã‚£ã‚¯ï¼ˆassumption, intro, split, left, right, add_dnï¼‰ã®å ´åˆã¯é™¤å¤–ï¼ˆæ­£è§£ãªã®ã§ï¼‰
                        basic_tactics = {"assumption", "intro", "split", "left", "right", "add_dn"}
                        if prover.goal is not None and include_failures and tactic_dict["main"] not in basic_tactics:
                            # æ–°ã—ã„ã‚´ãƒ¼ãƒ«ã‚’å–å¾—
                            new_state = encode_prover_state(prover)
                            new_goal = new_state["goal"]
                            
                            # äºŒé‡å¦å®šãƒ«ãƒ¼ãƒ—ãŒå«ã¾ã‚Œã¦ã„ãªã„å ´åˆã®ã¿è¿½åŠ 
                            if not detect_double_negation_loop(str(new_goal)):
                                example_failed_tactics.append({
                                "step_index": step,
                                "premises": current_premises.copy(),
                                "goal": current_goal,
                                "tactic": tactic_dict,
                                "tactic_apply": True,  # é©ç”¨ã¯æˆåŠŸã—ãŸãŒçµæœã¯è‰¯ããªã‹ã£ãŸ
                                "state_tactic_hash": state_tactic_hash,
                                "reward": 0.0,  # ä¸­é–“çš„ãªå¤±æ•—ã¨ã—ã¦0.0
                                "log_prob": np.log(selected_prob + 1e-8)
                            })
                        
                    else:
                        # å¤±æ•—ã—ãŸã‚¿ã‚¯ãƒ†ã‚£ã‚¯ã‚’è¨˜éŒ²
                        failed_tactic_strings.add(selected_tactic)
                        consecutive_failures += 1
                        
                        # å¤±æ•—ãƒ‡ãƒ¼ã‚¿ã‚‚è¨˜éŒ²ï¼ˆinclude_failuresãŒTrueã®å ´åˆï¼‰
                        # ãŸã ã—ã€äºŒé‡å¦å®šãƒ«ãƒ¼ãƒ—ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                        if include_failures and not detect_double_negation_loop(str(current_goal)):
                            tactic_dict = parse_tactic_string_cached(selected_tactic)
                            state_tactic_hash = create_state_hash(current_premises, current_goal, selected_tactic)
                            
                            example_failed_tactics.append({
                                "step_index": step,
                                "premises": current_premises.copy(),
                                "goal": current_goal,
                                "tactic": tactic_dict,
                                "tactic_apply": False,
                                "state_tactic_hash": state_tactic_hash,
                                "reward": failure_penalty,
                                "log_prob": np.log(selected_prob + 1e-8)  # å¯¾æ•°ç¢ºç‡
                            })
                        
                        # åˆ©ç”¨å¯èƒ½ãªã‚¿ã‚¯ãƒ†ã‚£ã‚¯ãƒªã‚¹ãƒˆã‚’æ›´æ–°
                        available_tactics = [tactic for tactic, _ in tactic_combinations 
                                           if tactic not in failed_tactic_strings]
                        
                        if not available_tactics:
                            example_terminated = True
                            break
                
                step += 1
                solved = prover.goal is None
            
            # æˆåŠŸãƒ»å¤±æ•—ãƒ‡ãƒ¼ã‚¿ã‚’é©åˆ‡ã«å‡¦ç†
            if solved:
                solved_count += 1
                successful_tactics.extend(example_successful_tactics)
                successful_buffer.extend(example_successful_tactics)
                
                # æˆåŠŸã—ãŸå ´åˆã§ã‚‚ã€ãã®éç¨‹ã§ã®å¤±æ•—ãƒ‡ãƒ¼ã‚¿ã‚’è¨˜éŒ²
                if include_failures:
                    # äºŒé‡å¦å®šãƒ«ãƒ¼ãƒ—ãŒå«ã¾ã‚Œã¦ã„ãªã„å¤±æ•—ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’è¿½åŠ 
                    filtered_failed_tactics = [
                        failed_tactic for failed_tactic in example_failed_tactics
                        if not detect_double_negation_loop(str(failed_tactic.get('goal', '')))
                    ]
                    failed_tactics.extend(filtered_failed_tactics)
                    failed_buffer.extend(filtered_failed_tactics)
            else:
                # è§£ã‘ãªã‹ã£ãŸå ´åˆã§ã‚‚ã€å¤±æ•—ãƒ‡ãƒ¼ã‚¿ã¯è¨˜éŒ²ã™ã‚‹ï¼ˆinclude_failuresãŒTrueã®å ´åˆï¼‰
                if include_failures:
                    # äºŒé‡å¦å®šãƒ«ãƒ¼ãƒ—ãŒå«ã¾ã‚Œã¦ã„ãªã„å¤±æ•—ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’è¿½åŠ 
                    filtered_failed_tactics = [
                        failed_tactic for failed_tactic in example_failed_tactics
                        if not detect_double_negation_loop(str(failed_tactic.get('goal', '')))
                    ]
                    failed_tactics.extend(filtered_failed_tactics)
                    failed_buffer.extend(filtered_failed_tactics)
            
            # ãƒãƒƒãƒ•ã‚¡ãŒä¸€å®šé‡ã«é”ã—ãŸã‚‰æ›¸ãå‡ºã—
            if output_dir and (len(successful_buffer) >= batch_size or len(failed_buffer) >= batch_size):
                batch_counter = save_buffer_data(
                    successful_buffer, failed_buffer, output_dir, batch_counter, batch_size, gcs_bucket, gcs_prefix
                )
                successful_buffer = []
                failed_buffer = []
                
            
                
        except Exception as e:
            # ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ãªã©ã§å¤±æ•—ã—ãŸå ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            continue
    
    # æ®‹ã‚Šã®ãƒãƒƒãƒ•ã‚¡ã‚’æ›¸ãå‡ºã—
    if output_dir and (successful_buffer or failed_buffer):
        batch_counter = save_buffer_data(
            successful_buffer, failed_buffer, output_dir, batch_counter, batch_size, gcs_bucket, gcs_prefix
        )
    
    return successful_tactics, failed_tactics


def clear_self_improvement_data(output_dir: str = "self_improvement_data") -> None:
    """Self improvementãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¯ãƒªã‚¢"""
    if os.path.exists(output_dir):
        import shutil
        shutil.rmtree(output_dir)
        print(f"Cleared existing data in {output_dir}")
    else:
        print(f"Directory {output_dir} does not exist, no need to clear")


def save_self_improvement_data(
    data: List[Dict[str, Any]],
    output_dir: str = "self_improvement_data",
    batch_size: int = 1000
) -> None:
    """Self improvementãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    os.makedirs(output_dir, exist_ok=True)
    
    # ãƒãƒƒãƒã”ã¨ã«åˆ†å‰²ã—ã¦ä¿å­˜
    for i in range(0, len(data), batch_size):
        batch_data = data[i:i + batch_size]
        batch_num = i // batch_size
        
        filename = f"training_data_{batch_num:05d}.json"
        filepath = os.path.join(output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(batch_data, f, ensure_ascii=False, indent=2)
        
        print(f"Saved {len(batch_data)} tactics to {filepath}")


def main():
    parser = argparse.ArgumentParser(description="Collect self improvement data from solved examples")
    parser.add_argument("--model_path", type=str, default="models/pretrained_model.pth", help="model path")
    parser.add_argument("--count", type=int, default=100, help="number of examples to process")
    parser.add_argument("--max_steps", type=int, default=30, help="max steps per example")
    parser.add_argument("--device", type=str, default="auto", help="device")
    parser.add_argument("--verbose", action="store_true", help="verbose output")
    parser.add_argument("--max_seq_len", type=int, default=256, help="maximum sequence length")
    parser.add_argument("--output_dir", type=str, default="self_improvement_data", help="output directory for collected data")
    parser.add_argument("--batch_size", type=int, default=1000, help="batch size for saving data")
    parser.add_argument("--generated_data_dir", type=str, default="generated_data", help="directory containing generated tautology data")
    parser.add_argument("--temperature", type=float, default=1.0, help="temperature for probabilistic tactic selection (higher = more random)")
    
    args = parser.parse_args()
    
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    if args.device == "auto":
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        device = torch.device(args.device)
    
    print(f"Using device: {device}")
    
    # ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
    if not os.path.exists(args.model_path):
        print(f"Model file not found: {args.model_path}")
        print("Please provide a valid model path.")
        return
    
    model, label_mappings = load_hierarchical_model(args.model_path, device)
    print(f"Loaded model from {args.model_path}")
    
    # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ä½œæˆ
    root_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
    token_py_path = os.path.join(root_dir, "src", "core", "fof_tokens.py")
    base_tokens, _ = load_tokens_and_labels_from_token_py(token_py_path)
    tokenizer = CharTokenizer(base_tokens=base_tokens)
    
    # ãƒ¢ãƒ‡ãƒ«ã®max_seq_lenã‚’å–å¾—
    checkpoint = torch.load(args.model_path, map_location=device)
    max_seq_len = checkpoint.get('max_seq_len', 256)
    
    print(f"Starting self improvement data collection...")
    print(f"  Examples to process: {args.count}")
    print(f"  Max steps per example: {args.max_steps}")
    print(f"  Temperature: {args.temperature}")
    print(f"  Generated data directory: {args.generated_data_dir}")
    print(f"  Output directory: {args.output_dir}")
    
    # æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
    clear_self_improvement_data(args.output_dir)
    
    # Self improvementãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    successful_tactics = collect_self_improvement_data(
        model=model,
        tokenizer=tokenizer,
        label_mappings=label_mappings,
        device=device,
        max_seq_len=max_seq_len,
        num_examples=args.count,
        max_steps=args.max_steps,
        verbose=args.verbose,
        generated_data_dir=args.generated_data_dir,
        temperature=args.temperature
    )
    
    if successful_tactics:
        # ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        save_self_improvement_data(
            data=successful_tactics,
            output_dir=args.output_dir,
            batch_size=args.batch_size
        )
    else:
        print("No successful tactics collected. Please check your model and parameters.")


if __name__ == "__main__":
    main()
