#!/usr/bin/env python3
"""
çœŸã®è¨¼æ˜æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ  - å®Ÿéš›ã«æˆ¦è¡“ã‚’é©ç”¨ã—ã¦è¨¼æ˜ã‚’æ¤œè¨¼
"""
import os
import sys
import torch
import json
import argparse
import time
from typing import List, Tuple, Dict, Any, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = os.path.dirname(os.path.dirname(__file__))
sys.path.insert(0, project_root)

from src.core.transformer_classifier import (
    load_tokens_and_labels_from_token_py,
    CharTokenizer,
    TransformerClassifier,
)

class ProofState:
    """è¨¼æ˜ã®çŠ¶æ…‹ã‚’ç®¡ç†"""
    
    def __init__(self, goal: str):
        self.goal = goal
        self.premises = []
        self.current_goal = goal
        self.step_count = 0
        self.is_proven = False
        
    def apply_tactic(self, tactic: str, arg1: str, arg2: str) -> bool:
        """æˆ¦è¡“ã‚’é©ç”¨ã—ã¦è¨¼æ˜çŠ¶æ…‹ã‚’æ›´æ–°"""
        self.step_count += 1
        
        if tactic == "assumption":
            # å‰æã‹ã‚‰ç›´æ¥è¨¼æ˜
            if self.current_goal in self.premises:
                self.is_proven = True
                return True
            return False
            
        elif tactic == "intro":
            # å«æ„ã®å°å…¥: A â†’ B ã‚’è¨¼æ˜ã™ã‚‹ãŸã‚ã« A ã‚’å‰æã«è¿½åŠ ã—ã¦ B ã‚’è¨¼æ˜
            if "â†’" in self.current_goal:
                # å«æ„ã®å·¦å´ã‚’å‰æã«è¿½åŠ 
                left_side = self.current_goal.split("â†’")[0].strip()
                self.premises.append(left_side)
                # å³å´ã‚’æ–°ã—ã„ç›®æ¨™ã«
                right_side = self.current_goal.split("â†’")[1].strip()
                self.current_goal = right_side
                return True
            return False
            
        elif tactic == "destruct":
            # è«–ç†ç©ã®åˆ†è§£: A âˆ§ B ã‹ã‚‰ A ã¨ B ã‚’åˆ†é›¢
            if "âˆ§" in self.current_goal:
                # è«–ç†ç©ã‚’åˆ†è§£
                parts = self.current_goal.split("âˆ§")
                for part in parts:
                    part = part.strip()
                    if part not in self.premises:
                        self.premises.append(part)
                return True
            return False
            
        elif tactic == "left":
            # è«–ç†å’Œã®å·¦å´: A âˆ¨ B ã‹ã‚‰ A ã‚’é¸æŠ
            if "âˆ¨" in self.current_goal:
                left_side = self.current_goal.split("âˆ¨")[0].strip()
                self.current_goal = left_side
                return True
            return False
            
        elif tactic == "right":
            # è«–ç†å’Œã®å³å´: A âˆ¨ B ã‹ã‚‰ B ã‚’é¸æŠ
            if "âˆ¨" in self.current_goal:
                right_side = self.current_goal.split("âˆ¨")[1].strip()
                self.current_goal = right_side
                return True
            return False
            
        elif tactic == "split":
            # è«–ç†å’Œã®åˆ†è§£: A âˆ¨ B ã‚’è¨¼æ˜ã™ã‚‹ãŸã‚ã« A ã¾ãŸã¯ B ã‚’è¨¼æ˜
            if "âˆ¨" in self.current_goal:
                # è«–ç†å’Œã®å·¦å´ã‚’è©¦ã™
                left_side = self.current_goal.split("âˆ¨")[0].strip()
                if self._try_prove(left_side):
                    return True
                # å³å´ã‚’è©¦ã™
                right_side = self.current_goal.split("âˆ¨")[1].strip()
                if self._try_prove(right_side):
                    return True
            return False
            
        return False
    
    def _try_prove(self, goal: str) -> bool:
        """ç›®æ¨™ã‚’è¨¼æ˜ã—ã‚ˆã†ã¨è©¦ã¿ã‚‹"""
        # ç°¡å˜ãªè¨¼æ˜ãƒã‚§ãƒƒã‚¯
        if goal in self.premises:
            return True
        if goal == "True":
            return True
        if goal in ["a", "b", "c"] and goal in self.premises:
            return True
        return False
    
    def check_proof_complete(self) -> bool:
        """è¨¼æ˜ãŒå®Œäº†ã—ãŸã‹ãƒã‚§ãƒƒã‚¯"""
        if self.is_proven:
            return True
        if self.current_goal in self.premises:
            return True
        if self.current_goal == "True":
            return True
        return False

def load_hierarchical_model(model_path: str, device: torch.device) -> Tuple[TransformerClassifier, Dict[str, Any]]:
    """éšå±¤åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
    checkpoint = torch.load(model_path, map_location=device)
    
    # ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
    if 'model_params' in checkpoint:
        model_params = checkpoint['model_params']
    else:
        model_params = {}
    
    vocab_size = checkpoint.get('vocab_size', 65)
    pad_id = checkpoint.get('pad_id', 0)
    max_seq_len = checkpoint.get('max_seq_len', 256)
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¯ãƒ©ã‚¹æ•°
    num_main_classes = 59
    num_arg1_classes = 10
    num_arg2_classes = 10
    
    # ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
    model = TransformerClassifier(
        vocab_size=vocab_size,
        pad_id=pad_id,
        max_seq_len=max_seq_len,
        d_model=model_params.get('d_model', 128),
        nhead=model_params.get('nhead', 8),
        num_layers=model_params.get('num_layers', 2),
        dim_feedforward=model_params.get('dim_feedforward', 256),
        dropout=model_params.get('dropout', 0.1),
        num_main_classes=num_main_classes,
        num_arg1_classes=num_arg1_classes,
        num_arg2_classes=num_arg2_classes,
    ).to(device)
    
    # ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’èª­ã¿è¾¼ã¿
    if 'model_state_dict' in checkpoint:
        model.load_state_dict(checkpoint['model_state_dict'])
    else:
        model.load_state_dict(checkpoint)
    
    model.eval()
    return model, {}

def get_tactic_name(tactic_id: int) -> str:
    """æˆ¦è¡“IDã‹ã‚‰æˆ¦è¡“åã‚’å–å¾—"""
    tactic_names = [
        "assumption", "intro", "apply", "destruct", "left", "right",
        "split", "exfalso", "contradiction", "exact", "reflexivity",
        "symmetry", "transitivity", "congruence", "rewrite", "unfold",
        "fold", "simpl", "auto", "tauto", "intuition", "omega",
        "ring", "field", "fourier", "psatz", "lia", "nia", "lra",
        "nra", "sos", "nsatz", "field_simplify", "ring_simplify",
        "algebra", "romega", "rtauto", "firstorder", "eauto",
        "autorewrite", "autounfold", "autosimpl", "autoreflect",
        "autorewrite_with", "autounfold_with", "autosimpl_with",
        "autoreflect_with", "autorewrite_with_clear", "autounfold_with_clear",
        "autosimpl_with_clear", "autoreflect_with_clear", "autorewrite_with_clear_clear",
        "autounfold_with_clear_clear", "autosimpl_with_clear_clear", "autoreflect_with_clear_clear"
    ]
    
    if 0 <= tactic_id < len(tactic_names):
        return tactic_names[tactic_id]
    else:
        return f"unknown_tactic_{tactic_id}"

def get_argument_name(arg_id: int, arg_type: str) -> str:
    """å¼•æ•°IDã‹ã‚‰å¼•æ•°åã‚’å–å¾—"""
    arg_names = ["0", "1", "2", "3", "4", "5", "6", "7", "8", "9"]
    
    if 0 <= arg_id < len(arg_names):
        return arg_names[arg_id]
    else:
        return f"unknown_{arg_type}_{arg_id}"

def real_proof_verification(model_path: str, test_count: int = 10, max_steps: int = 20, device: str = "auto"):
    """çœŸã®è¨¼æ˜æ¤œè¨¼ã‚’å®Ÿè¡Œ"""
    print(f"ğŸ§ª Real proof verification (actual tactic application)")
    print(f"  Model: {model_path}")
    print(f"  Test count: {test_count}")
    print(f"  Max steps: {max_steps}")
    
    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    if device == "auto":
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    else:
        device = torch.device(device)
    print(f"Using device: {device}")
    
    # ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
    model, _ = load_hierarchical_model(model_path, device)
    
    # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã‚’ä½œæˆ
    token_py_path = os.path.join(project_root, "src", "core", "fof_tokens.py")
    base_tokens, _ = load_tokens_and_labels_from_token_py(token_py_path)
    tokenizer = CharTokenizer(base_tokens)
    
    # ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    validation_file = os.path.join(project_root, "validation", "validation_tautology.json")
    with open(validation_file, 'r', encoding='utf-8') as f:
        validation_data = json.load(f)
    
    # ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠ
    import random
    test_samples = random.sample(validation_data, min(test_count, len(validation_data)))
    
    print(f"\nğŸ“Š Testing {len(test_samples)} samples with real proof verification...")
    
    solved_count = 0
    step_counts = []
    tactic_usage = {}
    
    for i, formula in enumerate(test_samples):
        if i % 5 == 0:  # 5ä¾‹ã”ã¨ã«é€²æ—è¡¨ç¤º
            print(f"  Progress: {i}/{len(test_samples)} ({i/len(test_samples)*100:.1f}%)")
        
        print(f"\n--- Sample {i+1}/{len(test_samples)} ---")
        print(f"Formula: {formula}")
        
        try:
            # è¨¼æ˜çŠ¶æ…‹ã‚’åˆæœŸåŒ–
            proof_state = ProofState(formula)
            
            # å®Ÿéš›ã®è¨¼æ˜ã‚’å®Ÿè¡Œ
            success, steps, tactics_used = execute_real_proof(
                model, tokenizer, proof_state, max_steps, device
            )
            
            step_counts.append(steps)
            
            # æˆ¦è¡“ä½¿ç”¨å›æ•°ã‚’è¨˜éŒ²
            for tactic in tactics_used:
                tactic_usage[tactic] = tactic_usage.get(tactic, 0) + 1
            
            if success:
                solved_count += 1
                print(f"âœ… Success (solved in {steps} steps)")
                print(f"   Final goal: {proof_state.current_goal}")
                print(f"   Premises: {proof_state.premises}")
            else:
                print(f"âŒ Failed (could not solve in {steps} steps)")
                print(f"   Final goal: {proof_state.current_goal}")
                print(f"   Premises: {proof_state.premises}")
                
        except Exception as e:
            print(f"âŒ Error during proof: {e}")
            step_counts.append(max_steps)
    
    # çµæœã‚’è¨ˆç®—
    total_examples = len(step_counts)
    success_rate = solved_count / total_examples if total_examples > 0 else 0.0
    avg_steps = sum(step_counts) / len(step_counts) if step_counts else 0
    
    print(f"\nğŸ“ˆ Results:")
    print(f"  Total examples: {total_examples}")
    print(f"  Solved: {solved_count}")
    print(f"  Success rate: {success_rate:.2%}")
    print(f"  Average steps: {avg_steps:.2f}")
    
    if tactic_usage:
        print(f"\nğŸ“Š Tactic usage:")
        for tactic, count in sorted(tactic_usage.items(), key=lambda x: x[1], reverse=True):
            print(f"  {tactic}: {count}")
    
    return {
        'success_rate': success_rate,
        'avg_steps': avg_steps,
        'solved_count': solved_count,
        'total_examples': total_examples,
        'tactic_usage': tactic_usage
    }

def execute_real_proof(model, tokenizer, proof_state, max_steps, device):
    """å®Ÿéš›ã®è¨¼æ˜ã‚’å®Ÿè¡Œ"""
    tactics_used = []
    
    for step in range(max_steps):
        try:
            # ç¾åœ¨ã®ç›®æ¨™ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            input_ids, attention_mask, segment_ids = tokenizer.encode(
                goal=proof_state.current_goal,
                premises=proof_state.premises,
                max_seq_len=256
            )
            
            # ãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ 
            input_ids = input_ids.unsqueeze(0).to(device)
            attention_mask = attention_mask.unsqueeze(0).to(device)
            segment_ids = segment_ids.unsqueeze(0).to(device)
            
            # ãƒ¢ãƒ‡ãƒ«æ¨è«–
            with torch.no_grad():
                main_logits, arg1_logits, arg2_logits = model(
                    input_ids, attention_mask, segment_ids
                )
                
                # äºˆæ¸¬ã‚’å–å¾—
                main_pred = torch.argmax(main_logits, dim=-1).item()
                arg1_pred = torch.argmax(arg1_logits, dim=-1).item()
                arg2_pred = torch.argmax(arg2_logits, dim=-1).item()
                
                # å®Ÿéš›ã®æˆ¦è¡“åã‚’å–å¾—
                tactic_name = get_tactic_name(main_pred)
                arg1_name = get_argument_name(arg1_pred, "arg1")
                arg2_name = get_argument_name(arg2_pred, "arg2")
                
                print(f"     Step {step + 1}: {tactic_name}({arg1_name}, {arg2_name})")
                
                # æˆ¦è¡“ã‚’å®Ÿéš›ã«é©ç”¨
                tactic_success = proof_state.apply_tactic(tactic_name, arg1_name, arg2_name)
                tactics_used.append(tactic_name)
                
                if not tactic_success:
                    print(f"       âŒ Tactic {tactic_name} failed to apply")
                    continue
                
                # è¨¼æ˜ãŒå®Œäº†ã—ãŸã‹ãƒã‚§ãƒƒã‚¯
                if proof_state.check_proof_complete():
                    print(f"       âœ… Proof completed!")
                    return True, step + 1, tactics_used
                
        except Exception as e:
            print(f"Error in step {step}: {e}")
            break
    
    return False, max_steps, tactics_used

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Real proof verification with actual tactic application")
    parser.add_argument("--model_path", type=str, default="../models/pretrained_model.pth", help="Path to model")
    parser.add_argument("--count", type=int, default=10, help="Number of test samples")
    parser.add_argument("--max_steps", type=int, default=20, help="Maximum steps")
    parser.add_argument("--device", type=str, default="auto", help="Device to use")
    
    args = parser.parse_args()
    
    results = real_proof_verification(args.model_path, args.count, args.max_steps, args.device)
    
    print(f"\nğŸ¯ Final Results:")
    print(f"  Success Rate: {results['success_rate']:.2%}")
    print(f"  Average Steps: {results['avg_steps']:.2f}")
    print(f"  Solved: {results['solved_count']}/{results['total_examples']}")

