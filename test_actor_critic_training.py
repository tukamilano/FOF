#!/usr/bin/env python3
"""
Actor-CriticÂ≠¶Áøí„ÅÆ„ÉÜ„Çπ„Éà„Çπ„ÇØ„É™„Éó„Éà
"""
import os
import sys
import torch
import json

# „Éó„É≠„Ç∏„Çß„ÇØ„Éà„É´„Éº„Éà„Çí„Éë„Çπ„Å´ËøΩÂä†
project_root = os.path.dirname(__file__)
sys.path.insert(0, project_root)

from src.core.transformer_classifier import (
    load_tokens_and_labels_from_token_py,
    CharTokenizer,
    build_hierarchical_label_mappings,
)
from src.core.parameter import get_model_params, get_hierarchical_labels
from src.core.actor_critic_model import create_actor_critic_model
from src.training.actor_critic_trainer import train_actor_critic
from src.interaction.self_improvement_data_collector import collect_comprehensive_rl_data


def test_actor_critic_training():
    """Actor-CriticÂ≠¶Áøí„Çí„ÉÜ„Çπ„Éà"""
    print("üß™ Testing Actor-Critic training...")
    
    # „Éá„Éê„Ç§„ÇπË®≠ÂÆö
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    # „Éë„É©„É°„Éº„Çø„ÇíÂàùÊúüÂåñ
    model_params = get_model_params()
    hierarchical_labels = get_hierarchical_labels()
    
    # „Éà„Éº„ÇØ„É≥„Å®„É©„Éô„É´„ÇíË™≠„ÅøËæº„Åø
    token_py_path = os.path.join(project_root, "src", "core", "fof_tokens.py")
    base_tokens, _ = load_tokens_and_labels_from_token_py(token_py_path)
    
    # ÈöéÂ±§ÂàÜÈ°ûÁî®„ÅÆ„É©„Éô„É´„Éû„ÉÉ„Éî„É≥„Ç∞„ÇíÊßãÁØâ
    main_to_id, arg1_to_id, arg2_to_id, id_to_main, id_to_arg1, id_to_arg2 = build_hierarchical_label_mappings(
        hierarchical_labels.main_tactics,
        hierarchical_labels.arg1_values,
        hierarchical_labels.arg2_values
    )
    
    label_mappings = {
        'main_to_id': main_to_id,
        'arg1_to_id': arg1_to_id,
        'arg2_to_id': arg2_to_id,
        'id_to_main': id_to_main,
        'id_to_arg1': id_to_arg1,
        'id_to_arg2': id_to_arg2
    }
    
    # „Éà„Éº„ÇØ„Éä„Ç§„Ç∂„Éº„Çí‰ΩúÊàê
    tokenizer = CharTokenizer(
        base_tokens=base_tokens,
        add_tactic_tokens=model_params.add_tactic_tokens,
        num_tactic_tokens=model_params.num_tactic_tokens
    )
    
    # Actor-Critic„É¢„Éá„É´„Çí‰ΩúÊàê
    print("üîÑ Creating Actor-Critic model...")
    model = create_actor_critic_model(
        pretrained_model_path="models/pretrained_model.pth",
        vocab_size=tokenizer.vocab_size,
        pad_id=tokenizer.pad_id,
        max_seq_len=256,
        num_main_classes=len(id_to_main),
        num_arg1_classes=len(id_to_arg1),
        num_arg2_classes=len(id_to_arg2),
        d_model=model_params.d_model,
        nhead=model_params.nhead,
        num_layers=model_params.num_layers,
        dim_feedforward=model_params.dim_feedforward,
        dropout=model_params.dropout,
        critic_hidden_dim=128,
        device=device
    )
    
    print("‚úÖ Actor-Critic model created successfully!")
    
    # „Éá„Éº„ÇøÂèéÈõÜÔºà„ÉÜ„Çπ„ÉàÁî®„Å´Â∞ë„Å™„ÇÅÔºâ
    print("\nüìä Collecting training data...")
    successful_tactics, failed_tactics = collect_comprehensive_rl_data(
        model=model.shared_encoder,  # ÂÖ±Êúâ„Ç®„É≥„Ç≥„Éº„ÉÄ„Éº„Çí‰ΩøÁî®
        tokenizer=tokenizer,
        label_mappings=label_mappings,
        device=device,
        max_seq_len=256,
        num_examples=10,  # „ÉÜ„Çπ„ÉàÁî®„Å´Â∞ë„Å™„ÇÅ
        max_steps=5,      # „ÉÜ„Çπ„ÉàÁî®„Å´Â∞ë„Å™„ÇÅ
        verbose=True,
        generated_data_dir="generated_data",
        temperature=1.0,
        include_failures=True,
        success_reward=1.0,
        step_penalty=0.01,
        failure_penalty=-0.1
    )
    
    print(f"üìà Data collection completed:")
    print(f"  Successful tactics: {len(successful_tactics)}")
    print(f"  Failed tactics: {len(failed_tactics)}")
    
    if len(successful_tactics) == 0 and len(failed_tactics) == 0:
        print("‚ùå No training data collected. Please check your data directory.")
        return
    
    # Actor-CriticÂ≠¶Áøí„ÇíÂÆüË°å
    print("\nüöÄ Starting Actor-Critic training...")
    history = train_actor_critic(
        model=model,
        successful_tactics=successful_tactics,
        failed_tactics=failed_tactics,
        tokenizer=tokenizer,
        device=device,
        num_epochs=3,  # „ÉÜ„Çπ„ÉàÁî®„Å´Â∞ë„Å™„ÇÅ
        batch_size=8,  # „ÉÜ„Çπ„ÉàÁî®„Å´Â∞ë„Å™„ÇÅ
        learning_rate=1e-4,
        kl_penalty_weight=0.1,
        entropy_weight=0.01,
        ppo_epochs=2,
        clip_ratio=0.2,
        value_coef=0.5,
        gamma=0.99,
        lam=0.95,
        use_amp=False,  # „ÉÜ„Çπ„ÉàÁî®„Å´ÁÑ°Âäπ
        use_wandb=False,
        max_seq_len=256
    )
    
    print("\nüìä Training completed!")
    print("Final losses:")
    for key, values in history.items():
        if values:
            print(f"  {key}: {values[-1]:.4f}")
    
    # „É¢„Éá„É´„Çí‰øùÂ≠ò
    model_path = "models/actor_critic_test.pth"
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    torch.save(model.state_dict(), model_path)
    print(f"üíæ Model saved to: {model_path}")
    
    # Â≠¶ÁøíÂ±•Ê≠¥„Çí‰øùÂ≠ò
    history_path = "logs/actor_critic_training_history.json"
    os.makedirs(os.path.dirname(history_path), exist_ok=True)
    with open(history_path, 'w') as f:
        json.dump(history, f, indent=2)
    print(f"üìà Training history saved to: {history_path}")
    
    # Á∞°Âçò„Å™Êé®Ë´ñ„ÉÜ„Çπ„Éà
    print("\nüîç Testing inference...")
    model.eval()
    
    # „ÉÜ„Çπ„ÉàÁî®„ÅÆÂÖ•Âäõ„Çí‰ΩúÊàê
    test_goal = "p -> p"
    test_premises = []
    input_ids, attention_mask, segment_ids = tokenizer.encode(
        test_goal, test_premises, 256
    )
    input_ids = input_ids.unsqueeze(0).to(device)
    attention_mask = attention_mask.unsqueeze(0).to(device)
    segment_ids = segment_ids.unsqueeze(0).to(device)
    
    # „Ç¢„ÇØ„Ç∑„Éß„É≥ÈÅ∏Êäû
    action_dict, log_prob, value = model.select_action(
        input_ids, attention_mask, segment_ids, temperature=1.0
    )
    
    print(f"Test inference result:")
    print(f"  Goal: {test_goal}")
    print(f"  Selected action: {action_dict}")
    print(f"  Log probability: {log_prob:.4f}")
    print(f"  Value: {value:.4f}")
    
    print("\nüéâ Actor-Critic training test completed successfully!")


if __name__ == "__main__":
    test_actor_critic_training()
